project: home-credit

name: home-credit-default-risk
tags: [solution-4]

metric:
  channel: 'ROC_AUC'
  goal: maximize

exclude:
  - output
  - notebooks
  - neptune.log
  - offline_job.log
  - .git
  - .github
  - .idea
  - .ipynb_checkpoints

parameters:
# Data
  train_filepath:                 ./data/application_train.csv
  test_filepath:                  ./data/application_test.csv
  bureau_balance_filepath:        ./data/bureau_balance.csv
  bureau_filepath:                ./data/bureau.csv
  credit_card_balance_filepath:   ./data/credit_card_balance.csv
  installments_payments_filepath: ./data/installments_payments.csv
  POS_CASH_balance_filepath:      ./data/POS_CASH_balance.csv
  previous_application_filepath:  ./data/previous_application.csv
  sample_submission_filepath:     ./data/sample_submission.csv
  first_level_oof_predictions_dir:  ./data/oof_predictions
  experiment_directory:           ./working

# Kaggle
  kaggle_api: 0
  kaggle_message: 'solution-4'

# Data preparation
  n_cv_splits: 5
  validation_size: 0.2
  stratified_cv: True
  shuffle: 1

# Execution
  clean_experiment_directory_before_training: 1
  num_workers: 25
  verbose: 1

# Preprocessing
  fill_missing: True
  fill_value: 0

# Feature Extraction
  installments__last_k_trend_periods: '[10, 50, 100, 500]'
  installments__last_k_agg_periods: '[1, 5, 10, 20, 50, 100]'
  installments__last_k_agg_period_fractions: '[(5,20),(5,50),(10,50),(10,100),(20,100)]'
  pos_cash__last_k_trend_periods: '[6, 12]'
  pos_cash__last_k_agg_periods: '[6, 12, 30]'
  application_aggregation__use_diffs_only: True
  use_nan_count: True
  max_corr_num: 32

# Light GBM
  lgbm_random_search_runs: 50
  lgbm__device: cpu # gpu cpu
  lgbm__boosting_type: gbdt
  lgbm__objective: binary
  lgbm__metric: auc
  lgbm__number_boosting_rounds: 10000
  lgbm__early_stopping_rounds: 200
  lgbm__learning_rate: '[0.0005, 0.1, "log-uniform"]'
  lgbm__num_leaves: '[20, 50]'
  lgbm__max_depth: '[7, 30]'
  lgbm__min_child_samples: '[20, 1000]'
  lgbm__max_bin: '[180, 500]' # at most 255 for device=gpu
  lgbm__subsample: '[0.8, 0.9, 0.99, 0.6, 0.7, "list"]'
  lgbm__subsample_freq: 1
  lgbm__colsample_bytree: 0.05
  lgbm__min_child_weight: '[0,40]'
  lgbm__reg_lambda: '[0.0, 0.1, "uniform"]'
  lgbm__reg_alpha: '[0.0, 0.1, "uniform"]'
  lgbm__scale_pos_weight: 1
  lgbm__is_unbalance: False
  lgbm__min_gain_to_split: 0.5

# XGBoost
  xgb_random_search_runs: 50
  xgb__booster: gbtree
  xgb__tree_method: hist # gpu_hist  # auto  hist
  xgb__objective: binary:logistic
  xgb__eval_metric: auc
  xgb__nrounds: 10000
  xgb__early_stopping_rounds: 100
  xgb__eta: '[0.001, 0.1, "log-uniform"]'
  xgb__max_leaves: '[21, 41, "choice"]'
  xgb__max_depth: 16
  xgb__max_bin: '[155, 355, "choice"]'
  xgb__subsample: '[0.5, 1., "uniform"]'
  xgb__colsample_bytree: '[0.5, 1., "uniform"]'
  xgb__colsample_bylevel: 1
  xgb__min_child_weight: 4
  xgb__lambda: '[0.00001, 1.0, "log-uniform"]'
  xgb__alpha: '[0.00001, 1.0, "log-uniform"]'
  xgb__scale_pos_weight: 1

# Random forest
  rf_random_search_runs: 50
  rf__n_estimators: '[100, 500]'
  rf__criterion: '["gini", "entropy", "list"]'
  rf__max_features: '[0.01, 0.5, "uniform"]'
  rf__min_samples_split: '[2, 50]'
  rf__min_samples_leaf: '[1, 50]'
  rf__class_weight: '[None, "balanced_subsample", "balanced", "list"]'

# Logistic regression
  lr_random_search_runs: 50
  lr__penalty: '["l2", "l1", "list"]'
  lr__tol: '[0.00001, 0.01, "log-uniform"]'
  lr__C: '[0.1, 100, "log-uniform"]'
  lr__fit_intercept: '[0, 1, "list"]'
  lr__class_weight: '[None, "balanced", "list"]'
  lr__solver: '["liblinear", "saga", "list"]'
  lr__max_iter: '[100, 1000, 10000, 50000, "list"]'

# SVC
  svc_random_search_runs: 50
  svc__kernel: '["poly", "rbf", "sigmoid", "list"]'
  svc__C: '[0.1, 100, "log-uniform"]'
  svc__degree: '[2, 7]'
  svc__gamma: auto
  svc__coef0: '[0.0, 1.0, "uniform"]'
  svc__probability: True
  svc__tol: '[0.00001, 0.01, "log-uniform"]'
  svc__max_iter: '[-1, 100, 1000, 10000, 50000, "list"]'

# Postprocessing
  aggregation_method: rank_mean
