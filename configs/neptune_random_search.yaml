project: ORGANIZATION/home-credit

name: home-credit-default-risk
tags: [solution-6]

metric:
  channel: 'ROC_AUC'
  goal: maximize

exclude:
  - output
  - notebooks
  - neptune.log
  - offline_job.log
  - .git
  - .github
  - .idea
  - .ipynb_checkpoints

parameters:
# Data
  train_filepath:                 YOUR/PATH/TO/application_train.csv
  test_filepath:                  YOUR/PATH/TO/application_test.csv
  bureau_balance_filepath:        YOUR/PATH/TO/bureau_balance.csv
  bureau_filepath:                YOUR/PATH/TO/bureau.csv
  credit_card_balance_filepath:   YOUR/PATH/TO/credit_card_balance.csv
  installments_payments_filepath: YOUR/PATH/TO/installments_payments.csv
  POS_CASH_balance_filepath:      YOUR/PATH/TO/POS_CASH_balance.csv
  previous_application_filepath:  YOUR/PATH/TO/previous_application.csv
  sample_submission_filepath:     YOUR/PATH/TO/sample_submission.csv
  first_level_oof_predictions_dir: YOUR/PATH/TO/oof_predictions
  experiment_directory:           YOUR/PATH/WORKDIR

# Kaggle
  kaggle_api: 0
  kaggle_message: 'solution-6'

# Data preparation
  n_cv_splits: 5
  validation_size: 0.2
  stratified_cv: True
  shuffle: 1

# Execution
  clean_experiment_directory_before_training: 1
  num_workers: 16
  verbose: 1

# Preprocessing
  fill_missing: False
  fill_value: None

# Feature Extraction
  installments__last_k_trend_periods: '[180, 360, 720]'
  installments__last_k_agg_periods: '[60, 180, 360, 720, 1500]'
  installments__last_k_agg_period_fractions: '[(60,180),(60,360),(180,1500),(360,1500)]'
  pos_cash__last_k_trend_periods: '[6, 12, 60]'
  pos_cash__last_k_agg_periods: '[6, 12, 24, 60]'
  pos_cash__last_k_agg_period_fractions: '[(6,24), (12, 60)]'
  bureau_balance__last_k_trend_periods: '[6, 12, 60]'
  bureau_balance__last_k_agg_periods: '[6, 12, 24, 60]'
  bureau_balance__last_k_agg_period_fractions: '[(6,24), (12, 60)]'
  application_aggregation__use_diffs_only: True
  use_nan_count: True

# Light GBM
  lgbm_random_search_runs: 50
  lgbm__device: cpu # gpu cpu
  lgbm__boosting_type: gbdt
  lgbm__objective: binary
  lgbm__metric: auc
  lgbm__number_boosting_rounds: 10000
  lgbm__early_stopping_rounds: 100
  lgbm__learning_rate: '[0.0005, 0.1, "log-uniform"]'
  lgbm__num_leaves: '[20, 50]'
  lgbm__max_depth: '[7, 30]'
  lgbm__min_child_samples: '[20, 50]'
  lgbm__max_bin: '[180, 500]' # at most 255 for device=gpu
  lgbm__subsample: '[0.8, 0.9, 0.99, 0.6, 0.7, "list"]'
  lgbm__subsample_freq: 0
  lgbm__colsample_bytree: 0.8
  lgbm__min_child_weight: 4
  lgbm__reg_lambda: '[0.0, 0.1, "uniform"]'
  lgbm__reg_alpha: '[0.0, 0.1, "uniform"]'
  lgbm__scale_pos_weight: 1
  lgbm__is_unbalance: False

# Catboost
  catboost_random_search_runs: 0
  catboost__loss_function: Logloss
  catboost__eval_metric: AUC
  catboost__iterations: 5000
  catboost__learning_rate: 0.05
  catboost__depth: 6
  catboost__l2_leaf_reg: 3
  catboost__border_count: 128
  catboost__model_size_reg: 0.5
  catboost__colsample_bylevel: 1.0

# XGBoost
  xgb_random_search_runs: 50
  xgb__booster: gbtree
  xgb__tree_method: hist # gpu_hist  # auto  hist
  xgb__objective: binary:logistic
  xgb__eval_metric: auc
  xgb__nrounds: 10000
  xgb__early_stopping_rounds: 100
  xgb__eta: '[0.001, 0.1, "log-uniform"]'
  xgb__max_leaves: '[21, 41, "choice"]'
  xgb__max_depth: 16
  xgb__max_bin: '[155, 355, "choice"]'
  xgb__subsample: '[0.5, 1., "uniform"]'
  xgb__colsample_bytree: '[0.5, 1., "uniform"]'
  xgb__colsample_bylevel: 1
  xgb__min_child_weight: 4
  xgb__lambda: '[0.00001, 1.0, "log-uniform"]'
  xgb__alpha: '[0.00001, 1.0, "log-uniform"]'
  xgb__scale_pos_weight: 1

# Random forest
  rf_random_search_runs: 50
  rf__n_estimators: '[100, 500]'
  rf__criterion: '["gini", "entropy", "list"]'
  rf__max_features: '[0.01, 0.5, "uniform"]'
  rf__min_samples_split: '[2, 50]'
  rf__min_samples_leaf: '[1, 50]'
  rf__class_weight: '[None, "balanced_subsample", "balanced", "list"]'

# Logistic regression
  lr_random_search_runs: 50
  lr__penalty: '["l2", "l1", "list"]'
  lr__tol: '[0.00001, 0.01, "log-uniform"]'
  lr__C: '[0.1, 100, "log-uniform"]'
  lr__fit_intercept: '[0, 1, "list"]'
  lr__class_weight: '[None, "balanced", "list"]'
  lr__solver: '["liblinear", "saga", "list"]'
  lr__max_iter: '[100, 1000, 10000, 50000, "list"]'

# SVC
  svc_random_search_runs: 50
  svc__kernel: '["poly", "rbf", "sigmoid", "list"]'
  svc__C: '[0.1, 100, "log-uniform"]'
  svc__degree: '[2, 7]'
  svc__gamma: auto
  svc__coef0: '[0.0, 1.0, "uniform"]'
  svc__probability: True
  svc__tol: '[0.00001, 0.01, "log-uniform"]'
  svc__max_iter: '[-1, 100, 1000, 10000, 50000, "list"]'

# Postprocessing
  aggregation_method: rank_mean
