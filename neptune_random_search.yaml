project: HC

name: home-credit-default-risk
tags: [solution-1]

metric:
  channel: 'ROC_AUC'
  goal: maximize

exclude:
  - output
  - imgs
  - neptune.log
  - offline_job.log
  - .git
  - .idea
  - .ipynb_checkpoints

parameters:
# Data
  train_filepath: YOUR/PATH
  test_filepath: YOUR/PATH
  sample_submission_filepath: YOUR/PATH
  experiment_dir: YOUR/PATH

# Validation
  target_bins: 100
  validation_size: 0.2

# Execution
  overwrite: 1
  num_workers: 10
  verbose: 1

# Preprocessing
  target_encoder__n_splits: 10

# Light GBM
  lgbm_random_search_runs: 100
  lgbm__boosting_type: gbdt
  lgbm__objective: binary
  lgbm__metric: auc
  lgbm__number_boosting_rounds: 1000
  lgbm__early_stopping_rounds: 30
  lgbm__learning_rate: '[0.01, 0.2, "uniform"]'
  lgbm__num_leaves: '[25, 35]'
  lgbm__max_depth: '[10, 20]'
  lgbm__min_child_samples: '[35, 45]'
  lgbm__max_bin: '[275, 325]'
  lgbm__subsample: '[0.8, 1., 1.2, "list"]'
  lgbm__subsample_freq: 5
  lgbm__colsample_bytree: 0.8
  lgbm__min_child_weight: 4
  lgbm__reg_lambda: 0.0
  lgbm__reg_alpha: 0.1
  lgbm__scale_pos_weight: 1

# Random forest
  rf_random_search_runs: 100
  rf__n_estimators: '[100, 200]'
  rf__max_features: '["auto", "log2", "list"]'
  rf__max_depth: '[5, 30]'
  rf__min_samples_split: '[2, 50]'
  rf__min_samples_leaf: '[1, 50]'
  rf__min_weight_fraction_leaf: '[0.0, 0.2, "uniform"]'

#Logistic regression
  lr_random_search_runs: 100
  lr__penalty: '["l2", "l1", "list"]'
  lr__tol: '[0.0001, 0.01, "log-uniform"]'
  lr__C: '[0.1, 1000, "log-uniform"]'
  lr__solver: '["liblinear", "saga", "list"]'